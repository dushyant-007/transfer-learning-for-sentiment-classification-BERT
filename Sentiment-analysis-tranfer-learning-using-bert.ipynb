{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Necessary Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:35.252927500Z",
     "start_time": "2023-05-27T20:18:31.841033100Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting data from data/sentiment_train.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5668 entries, 0 to 5667\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  5668 non-null   object\n",
      " 1   label     5668 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.7+ KB\n",
      "None\n",
      "                                            sentence  label\n",
      "0    Ok brokeback mountain is such a horrible movie.      0\n",
      "1                 Brokeback Mountain was so awesome.      1\n",
      "2  friday hung out with kelsie and we went and sa...      0\n",
      "3  I am going to start reading the Harry Potter s...      1\n",
      "4       Is it just me, or does Harry Potter suck?...      0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/sentiment_train.csv')\n",
    "print(data.info())\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:35.317053100Z",
     "start_time": "2023-05-27T20:18:35.257367200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above is how the data looks\n",
    "\n",
    "Now let us work on it a little bit\n",
    "\n",
    "1. Make train - test splits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train is (3627,)\n",
      "shape of x_test is (1134,)\n",
      "shape of x_val is (907,)\n",
      "shape of y_train is (3627,)\n",
      "shape of y_test is (1134,)\n",
      "shape of y_validation is (907,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr , x_te , y_tr, y_te = train_test_split(data['sentence'].values,\n",
    "                                            data['label'].values,\n",
    "                                            train_size=0.8,\n",
    "                                            random_state=1)\n",
    "\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_tr,\n",
    "                                          y_tr,\n",
    "                                          train_size=0.8,\n",
    "                                          random_state=1)\n",
    "\n",
    "print(f'shape of x_train is {x_tr.shape}')\n",
    "print(f'shape of x_test is {x_te.shape}')\n",
    "print(f'shape of x_val is {x_va.shape}')\n",
    "print(f'shape of y_train is {y_tr.shape}')\n",
    "print(f'shape of y_test is {y_te.shape}')\n",
    "print(f'shape of y_validation is {y_va.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:39.623009400Z",
     "start_time": "2023-05-27T20:18:37.981029400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:39.718677500Z",
     "start_time": "2023-05-27T20:18:39.693686900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:43.152515Z",
     "start_time": "2023-05-27T20:18:40.092186600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see , what should be the padding length. I want to take the median"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([1340.,  700.,  583.,  443.,  188.,  168.,   99.,   22.,   80.,\n           4.]),\n array([ 3. ,  6.7, 10.4, 14.1, 17.8, 21.5, 25.2, 28.9, 32.6, 36.3, 40. ]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_of_sentences_in_train_data = [len(i.split()) for i in x_tr]\n",
    "plt.hist(len_of_sentences_in_train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:43.506722800Z",
     "start_time": "2023-05-27T20:18:43.154657Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From looking at the histogram , I think we should take 15 to be the padding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alright, Now let's tokenize the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dushyant S. Udawat\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pad_len = 15\n",
    "\n",
    "x_tr_token = tokenizer.batch_encode_plus(\n",
    "    x_tr.tolist(),\n",
    "    max_length= pad_len,\n",
    "    pad_to_max_length = True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "x_va_token = tokenizer.batch_encode_plus(\n",
    "    x_va.tolist(),\n",
    "    max_length=pad_len,\n",
    "    pad_to_max_length = True,\n",
    "    truncation= True\n",
    ")\n",
    "\n",
    "x_te_token = tokenizer.batch_encode_plus(\n",
    "    x_te.tolist(),\n",
    "    max_length=pad_len,\n",
    "    pad_to_max_length = True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# getting the sequence data\n",
    "x_tr_seq = torch.tensor(x_tr_token['input_ids'])\n",
    "x_va_seq = torch.tensor(x_va_token['input_ids'])\n",
    "x_te_seq = torch.tensor(x_te_token['input_ids'])\n",
    "\n",
    "# getting the attention mask\n",
    "x_tr_mask = torch.tensor(x_tr_token['attention_mask'])\n",
    "x_te_mask = torch.tensor(x_te_token['attention_mask'])\n",
    "x_va_mask = torch.tensor(x_va_token['attention_mask'])\n",
    "\n",
    "# getting the labels\n",
    "y_tr = torch.tensor(y_tr.tolist())\n",
    "y_va = torch.tensor(y_va.tolist())\n",
    "y_te = torch.tensor(y_te.tolist())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:46.015558Z",
     "start_time": "2023-05-27T20:18:45.864206900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:48.038646400Z",
     "start_time": "2023-05-27T20:18:48.023026600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045,  2066,  ...,  1055,  2006,   102],\n",
      "        [  101,  1045,  2293,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  ...,  3791,  1037,   102],\n",
      "        ...,\n",
      "        [  101,  4302, 10693,  ...,  2758, 11543,   102],\n",
      "        [  101,  2029,  2003,  ...,  2480,  1045,   102],\n",
      "        [  101,  4830, 23765,  ...,     0,     0,     0]])\n",
      "the shape of the x_tr_seq is torch.Size([3627, 15])\n"
     ]
    }
   ],
   "source": [
    "print(x_tr_seq)\n",
    "print(f'the shape of the x_tr_seq is {x_tr_seq.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:48.336527100Z",
     "start_time": "2023-05-27T20:18:48.304674300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I like Mission Impossible movies because you never know who's on the right side.\"\n",
      " 'I love Harry Potter..'\n",
      " 'I hate Harry Potter, that daniel wotshisface needs a fucking slap...']\n",
      "tensor([[  101,  1045,  2066,  3260,  5263,  5691,  2138,  2017,  2196,  2113,\n",
      "          2040,  1005,  1055,  2006,   102],\n",
      "        [  101,  1045,  2293,  4302, 10693,  1012,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  4302, 10693,  1010,  2008,  3817, 24185,  3215,\n",
      "         24158, 12172,  3791,  1037,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(x_tr[:3])\n",
    "\n",
    "print(x_tr_seq[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:49.094461700Z",
     "start_time": "2023-05-27T20:18:49.069626500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, as can be seen the tokenizer just makes the sentence into dictionary indexes. It is nothing special , there is no machine learning here. However, we should remember that the dictionary indexes here are related to their corresponding embeddings in the trained bert model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_arch, self).__init__()\n",
    "        self.bert = bert\n",
    "\n",
    "        # adding a dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # relu\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "\n",
    "        # dense layer 2\n",
    "        self. fc2 = nn.Linear(512, 2)\n",
    "\n",
    "        # softmax activation\n",
    "        self.softmax = nn.LogSoftmax(dim =1 )\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:52.931112500Z",
     "start_time": "2023-05-27T20:18:52.916959100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = BERT_arch(bert)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 1e-5)  # learning rate\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:18:54.583628800Z",
     "start_time": "2023-05-27T20:18:54.552947700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# making the data_loaders here\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "training_data = TensorDataset(x_tr_seq, x_tr_mask, y_tr)\n",
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
    "testing_data = TensorDataset(x_te_seq, x_te_mask, y_te)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=16, shuffle=False)\n",
    "validation_data = TensorDataset(x_va_seq, x_va_mask, y_va)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=16, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:29:17.149542100Z",
     "start_time": "2023-05-27T20:29:17.130799800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, device, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses , accuracy = [], []\n",
    "\n",
    "\n",
    "    for step , batch in enumerate(train_dataloader):\n",
    "\n",
    "        # progress update after every 50 batches.\n",
    "        if step%50 == 0 :\n",
    "                print(f'at step {step}, the len of dataloader is {len(train_dataloader)}')\n",
    "\n",
    "        # pushing to device\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id , mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # backward the loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update the gradients of the model\n",
    "        optimizer.step()\n",
    "\n",
    "        # printout the results.\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracy.append(sum(preds.detach().argmax(dim=1) == labels))\n",
    "        print(f'step - {step}, the loss is {losses[-1]}, accuracy is {accuracy[-1]}')\n",
    "\n",
    "\n",
    "    return losses, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:56:18.099042700Z",
     "start_time": "2023-05-27T20:56:18.079332500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step 0, the len of dataloader is 227\n",
      "step - 0, the loss is 0.6196637749671936, accuracy is 12\n",
      "step - 1, the loss is 0.6625979542732239, accuracy is 10\n",
      "step - 2, the loss is 0.7283103466033936, accuracy is 7\n",
      "step - 3, the loss is 0.7403846383094788, accuracy is 7\n",
      "step - 4, the loss is 0.6804380416870117, accuracy is 9\n",
      "step - 5, the loss is 0.6638210415840149, accuracy is 11\n",
      "step - 6, the loss is 0.6879505515098572, accuracy is 8\n",
      "step - 7, the loss is 0.7474181652069092, accuracy is 6\n",
      "step - 8, the loss is 0.6454638242721558, accuracy is 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCrossEntropyLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[42], line 21\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_dataloader, device, loss_fn, optimizer)\u001B[0m\n\u001B[0;32m     18\u001B[0m model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# get model predictions for the current batch\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msent_id\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# compute the loss between actual and predicted values\u001B[39;00m\n\u001B[0;32m     24\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(preds, labels)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[9], line 25\u001B[0m, in \u001B[0;36mBERT_arch.forward\u001B[1;34m(self, sent_id, mask)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, sent_id, mask):\n\u001B[1;32m---> 25\u001B[0m     _, cls_hs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\u001B[43msent_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(cls_hs)\n\u001B[0;32m     29\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1005\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1007\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1008\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1009\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1020\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1027\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    594\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    595\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    596\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    600\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    601\u001B[0m     )\n\u001B[0;32m    602\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 603\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    479\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    488\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    411\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    417\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    418\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 419\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    429\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:308\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    307\u001B[0m     key_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkey(hidden_states))\n\u001B[1;32m--> 308\u001B[0m     value_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    310\u001B[0m query_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(mixed_query_layer)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder:\n\u001B[0;32m    313\u001B[0m     \u001B[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001B[39;00m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "train(model, train_dataloader, device, nn.CrossEntropyLoss(), optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:59:16.913753400Z",
     "start_time": "2023-05-27T20:56:18.439619100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# implementing the evaluate function here.\n",
    "\n",
    "def evaluate(model, val_dataloader, loss_fn, device):\n",
    "\n",
    "    print('\\nEvaluating ... ')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    losses, accuracy = [], []\n",
    "\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "\n",
    "        # extract the data from the batch\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        input_ids, mask, labels = batch\n",
    "\n",
    "\n",
    "        # pass through the model to produce outputs\n",
    "        pred = model(input_ids, mask)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        #\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracy.append(sum(pred.detach().argmax(dim=1) == labels))\n",
    "        print(f'step - {step}, the loss is {losses[-1]}, accuracy is {accuracy[-1]}')\n",
    "\n",
    "    return losses, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:52:34.526729Z",
     "start_time": "2023-05-27T20:52:34.526729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ... \n",
      "step - 0, the loss is 0.6556817889213562, accuracy is 11\n",
      "step - 1, the loss is 0.724297285079956, accuracy is 6\n",
      "step - 2, the loss is 0.6563833355903625, accuracy is 11\n",
      "step - 3, the loss is 0.648156464099884, accuracy is 11\n",
      "step - 4, the loss is 0.642035961151123, accuracy is 11\n",
      "step - 5, the loss is 0.6359774470329285, accuracy is 12\n",
      "step - 6, the loss is 0.7056006193161011, accuracy is 8\n",
      "step - 7, the loss is 0.6691660284996033, accuracy is 9\n",
      "step - 8, the loss is 0.6814170479774475, accuracy is 9\n",
      "step - 9, the loss is 0.6367151141166687, accuracy is 12\n",
      "step - 10, the loss is 0.7182621359825134, accuracy is 6\n",
      "step - 11, the loss is 0.7205774188041687, accuracy is 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCrossEntropyLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[40], line 21\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, val_dataloader, loss_fn, device)\u001B[0m\n\u001B[0;32m     17\u001B[0m input_ids, mask, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# pass through the model to produce outputs\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# calculate the loss\u001B[39;00m\n\u001B[0;32m     24\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, labels)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[9], line 25\u001B[0m, in \u001B[0;36mBERT_arch.forward\u001B[1;34m(self, sent_id, mask)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, sent_id, mask):\n\u001B[1;32m---> 25\u001B[0m     _, cls_hs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\u001B[43msent_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(cls_hs)\n\u001B[0;32m     29\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1005\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1007\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1008\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1009\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1020\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1027\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    594\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    595\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    596\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    600\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    601\u001B[0m     )\n\u001B[0;32m    602\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 603\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    479\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    488\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    411\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    417\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    418\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 419\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    429\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:307\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    305\u001B[0m     value_layer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([past_key_value[\u001B[38;5;241m1\u001B[39m], value_layer], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 307\u001B[0m     key_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    308\u001B[0m     value_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue(hidden_states))\n\u001B[0;32m    310\u001B[0m query_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(model, val_dataloader, nn.CrossEntropyLoss(), device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T20:56:12.707867900Z",
     "start_time": "2023-05-27T20:52:35.261687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now let's test on new data\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(x_te_seq.to(device), x_te_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "pred = np.argmax(preds, axis =1)\n",
    "print(classification_report(y_te, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-27T21:02:21.413167400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
